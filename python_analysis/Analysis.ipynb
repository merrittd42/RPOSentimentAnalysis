{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweets(df):\n",
    "    temp_df = df.copy()\n",
    "    \n",
    "    #This code removes all links, mentions, numbers and rows mentioning FUNKO POPS\n",
    "    temp_df.drop_duplicates(['SentimentText'], keep='first')\n",
    "    temp_df = temp_df[temp_df.SentimentText.str.contains(\"Funko\") == False]\n",
    "    temp_df = temp_df[temp_df.SentimentText.str.contains(\"funko\") == False]\n",
    "    temp_df = temp_df[temp_df.SentimentText.str.contains(\"For a chance to #WIN\") == False]\n",
    "    temp_df = temp_df[temp_df.SentimentText.str.contains(\"For a chance to WIN\") == False]\n",
    "    temp_df = temp_df[temp_df.SentimentText.str.contains(\"for a chance to win\") == False]\n",
    "    temp_df = temp_df[temp_df.SentimentText.str.contains(\"for a chance to WIN\") == False]\n",
    "    temp_df = temp_df[temp_df.SentimentText.str.contains(\"for your chance to win\") == False]\n",
    "    temp_df = temp_df[temp_df.SentimentText.str.contains(\"For your chance to WIN\") == False]\n",
    "    temp_df.SentimentText = [re.sub(r\"https?:\\/\\/.*\\/[a-zA-Z0-9]*\", \"\", w) for w in temp_df.SentimentText]\n",
    "    temp_df.SentimentText = [re.sub(r\"https?:\\/\\/.*\\/[a-zA-Z0-9]*\", \"\", w) for w in temp_df.SentimentText]\n",
    "    temp_df.SentimentText = [re.sub(r\"&amp;quot;|&amp;amp'\", \"\", w) for w in temp_df.SentimentText]\n",
    "    temp_df.SentimentText = [re.sub(r\"@[a-zA-Z0-9]*\", \"\", w) for w in temp_df.SentimentText]\n",
    "    temp_df.SentimentText = [re.sub(r\"\\$[a-zA-Z0-9]*\", \"\", w) for w in temp_df.SentimentText]\n",
    "    temp_df.SentimentText = [re.sub(r\"[0-9]*\", \"\", w) for w in temp_df.SentimentText]\n",
    "    temp_df.SentimentText = [w.strip() for w in temp_df.SentimentText]\n",
    "    \n",
    "    temp_df.SentimentText = temp_df.SentimentText.str.replace('[^\\w\\s]','')\n",
    "        \n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating DF and Cleaning Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 8836: expected 4 fields, saw 5\\n'\n",
      "b'Skipping line 535882: expected 4 fields, saw 7\\n'\n"
     ]
    }
   ],
   "source": [
    "# skips problem lines for now\n",
    "df = pd.read_csv(\"Sentiment Analysis Dataset.csv\",error_bad_lines=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = clean_tweets(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(clean_df.SentimentText, clean_df.Sentiment, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_train = CountVectorizer()\n",
    "X_train = vectorizer_train.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train)\n",
    "X_train_tf = tf_transformer.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_test = CountVectorizer(vocabulary=vectorizer_train.vocabulary_)\n",
    "X_test = vectorizer_test.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_tf,y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.82      0.79    157670\n",
      "          1       0.80      0.75      0.78    158053\n",
      "\n",
      "avg / total       0.78      0.78      0.78    315723\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = BernoulliNB()\n",
    "clf.fit(X_train_tf,y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.78      0.78    157670\n",
      "          1       0.78      0.78      0.78    158053\n",
      "\n",
      "avg / total       0.78      0.78      0.78    315723\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC()\n",
    "clf.fit(X_train_tf,y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_tf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.87      0.81    157670\n",
      "          1       0.85      0.71      0.77    158053\n",
      "\n",
      "avg / total       0.80      0.79      0.79    315723\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet list length before cleaning: 79902\n",
      "Tweet list after cleaning: 46649\n",
      "1556\n"
     ]
    }
   ],
   "source": [
    "tdf = pd.read_csv(\"tweetList.csv\",error_bad_lines=False, encoding='utf-8')\n",
    "print(\"Tweet list length before cleaning: \" + str(len(tdf.index)))\n",
    "cleaned_tweets = clean_tweets(tdf)\n",
    "print(\"Tweet list after cleaning: \" + str(len(cleaned_tweets.index)))\n",
    "apr10df = cleaned_tweets[cleaned_tweets.date.str.contains(\"Apr 10\") == True]\n",
    "apr9df = cleaned_tweets[cleaned_tweets.date.str.contains(\"Apr 09\") == True]\n",
    "apr8df = cleaned_tweets[cleaned_tweets.date.str.contains(\"Apr 08\") == True]\n",
    "apr7df = cleaned_tweets[cleaned_tweets.date.str.contains(\"Apr 07\") == True]\n",
    "apr6df = cleaned_tweets[cleaned_tweets.date.str.contains(\"Apr 06\") == True]\n",
    "apr5df = cleaned_tweets[cleaned_tweets.date.str.contains(\"Apr 05\") == True]\n",
    "apr4df = cleaned_tweets[cleaned_tweets.date.str.contains(\"Apr 04\") == True]\n",
    "apr3df = cleaned_tweets[cleaned_tweets.date.str.contains(\"Apr 03\") == True]\n",
    "apr2df = cleaned_tweets[cleaned_tweets.date.str.contains(\"Apr 02\") == True]\n",
    "apr1df = cleaned_tweets[cleaned_tweets.date.str.contains(\"Apr 01\") == True]\n",
    "mar31df = cleaned_tweets[cleaned_tweets.date.str.contains(\"Mar 31\") == True]\n",
    "print(len(apr10df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
